#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤
–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è project_translator.py
"""

import os
import sys
import json
import argparse
from pathlib import Path

def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞"""
    config_path = Path(__file__).parent / "translation_config.json"
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def get_api_key_from_env(provider: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    env_vars = {
        "groq": "GROQ_API_KEY",
        "openai": "OPENAI_API_KEY", 
        "anthropic": "ANTHROPIC_API_KEY"
    }
    
    key = os.getenv(env_vars.get(provider, ""))
    if not key:
        print(f"‚ö†Ô∏è  API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è {env_vars.get(provider, '')}")
        print(f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: export {env_vars.get(provider, '')}='your-api-key'")
    return key

def main():
    config = load_config()
    default_config = config.get("default_config", {})
    
    parser = argparse.ArgumentParser(description="üöÄ –ë—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤")
    parser.add_argument("project", help="–ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
    parser.add_argument("-l", "--lang", default=default_config.get("target_language", "English"), 
                       help="–¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: English)")
    parser.add_argument("-p", "--provider", choices=["groq", "openai", "anthropic"], 
                       default=default_config.get("llm_provider", "groq"), 
                       help="LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä")
    parser.add_argument("-m", "--model", help="–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    parser.add_argument("-c", "--concurrent", type=int, 
                       default=default_config.get("max_concurrent_requests", 10),
                       help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
    parser.add_argument("--chunk-size", type=int, 
                       default=default_config.get("chunk_size", 150),
                       help="–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å—Ç—Ä–æ–∫–∞—Ö")
    parser.add_argument("--dry-run", action="store_true", help="–¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑, –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞")
    parser.add_argument("--chinese", action="store_true", help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã")
    parser.add_argument("--formal", action="store_true", help="–§–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–æ–Ω –ø–µ—Ä–µ–≤–æ–¥–∞")
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
    if not os.path.exists(args.project):
        print(f"‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.project}")
        sys.exit(1)
    
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á
    api_key = get_api_key_from_env(args.provider)
    if not api_key and not args.dry_run:
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å
    if not args.model:
        models = config.get("llm_providers", {}).get(args.provider, {}).get("models", [])
        if models:
            args.model = models[0]
        else:
            print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {args.provider}")
            sys.exit(1)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    custom_instructions = []
    templates = config.get("custom_instructions_templates", {})
    
    if args.chinese:
        custom_instructions.append(templates.get("preserve_chinese", ""))
    if args.formal:
        custom_instructions.append(templates.get("formal_tone", ""))
    
    custom_instructions_str = " ".join(custom_instructions)
    
    print("üéØ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞:")
    print(f"   –ü—Ä–æ–µ–∫—Ç: {args.project}")
    print(f"   –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫: {args.lang}")
    print(f"   –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {args.provider}")
    print(f"   –ú–æ–¥–µ–ª—å: {args.model}")
    print(f"   –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {args.chunk_size}")
    print(f"   –û–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {args.concurrent}")
    if custom_instructions_str:
        print(f"   –î–æ–ø. –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: {custom_instructions_str[:100]}...")
    
    if args.dry_run:
        print("\nüîç –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ –∞–Ω–∞–ª–∏–∑–∞...")
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ API –≤—ã–∑–æ–≤–æ–≤
        from project_translator import ProjectAnalyzer, TranslationConfig
        
        config_obj = TranslationConfig(
            source_project_path=args.project,
            target_language=args.lang,
            chunk_size=args.chunk_size
        )
        
        analyzer = ProjectAnalyzer(config_obj)
        project_info = analyzer.analyze_project(args.project)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {project_info['total_files']}")
        print(f"   –î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: {project_info['translatable_files']}")
        print(f"   –û–∂–∏–¥–∞–µ–º–æ —á–∞–Ω–∫–æ–≤: {project_info['estimated_chunks']}")
        print(f"   –¢–∏–ø—ã —Ñ–∞–π–ª–æ–≤: {project_info['file_types']}")
        
        estimated_cost_groq = project_info['estimated_chunks'] * 0.001  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞ —á–∞–Ω–∫
        print(f"\nüí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å (Groq): ~${estimated_cost_groq:.2f}")
        
        return
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç
    try:
        import asyncio
        from project_translator import ProjectTranslator, TranslationConfig
        
        config_obj = TranslationConfig(
            source_project_path=args.project,
            target_language=args.lang,
            chunk_size=args.chunk_size,
            custom_instructions=custom_instructions_str,
            llm_provider=args.provider,
            api_key=api_key,
            model_name=args.model,
            max_concurrent_requests=args.concurrent
        )
        
        translator = ProjectTranslator(config_obj)
        asyncio.run(translator.translate_project())
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:")
        if args.provider == "groq":
            print("pip install groq")
        elif args.provider == "openai":
            print("pip install openai")
        elif args.provider == "anthropic":
            print("pip install anthropic")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
